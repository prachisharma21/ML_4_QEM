{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random_VQE_data_prep\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_gate_paris(df, gates:str):\n",
    "    l = df[gates]\n",
    "    res = dict()\n",
    "    for i in range(len(l)):\n",
    "        tmp = str(l[i])\n",
    "        if tmp in res.keys():\n",
    "            res[tmp] += 1\n",
    "        else:\n",
    "            res[tmp] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path):\n",
    "    file = open(path, \"rb\")\n",
    "    dict_ = pickle.load(file)\n",
    "    #print(dict)\n",
    "    #print(len(dict[\"Quantum_circuit\"]))\n",
    "    data = dict_[\"Quantum_circuit\"][0].__dict__[\"_data\"]\n",
    "    #print(dict[\"Quantum_circuit\"][0].draw())\n",
    "    \n",
    "\n",
    "    qubits = str(data)\n",
    "    #print(qubits)\n",
    "\n",
    "    # Split input_string before each \"CircuitInstruction\"\n",
    "    instructions = qubits.split(\"CircuitInstruction\")\n",
    "\n",
    "    # Remove the empty string at the beginning (resulting from the initial split)\n",
    "    instructions = instructions[1:]\n",
    "\n",
    "    #patterns to get different values from datastring\n",
    "    pattern_nq = r\"num_qubits=(\\d+)\"\n",
    "    pattern_nc = r\"num_clbits=(\\d+)\"\n",
    "    pattern_n = r\"name='(\\w+)'\"\n",
    "    pattern_p = r\"params=\\[(.*?)\\]\"\n",
    "    pattern_gates = r\"Qubit\\(QuantumRegister\\(5, 'q'\\), (\\d+)\\)\"\n",
    "    #pattern_clb = r'clbits=\\(\\)\\)' -> possibly clbits relevant?\n",
    "\n",
    "    # Extracted numbers\n",
    "    # find all values and store them in array to build df\n",
    "    numbers = [int(match) for match in re.findall(pattern_nq, qubits)]\n",
    "    clbits = [int(match_cl) for match_cl in re.findall(pattern_nq, qubits)]\n",
    "    name = [match_name for match_name in re.findall(pattern_n, qubits)]\n",
    "    params = [match_p for match_p in re.findall(pattern_p, qubits)]\n",
    "\n",
    "    # loop over all Instructions to get per instruction a list of used qubits\n",
    "    gates_all = []\n",
    "    for instr in enumerate(instructions):\n",
    "        gates = [match_gates for match_gates in re.findall(pattern_gates, str(instr))]\n",
    "        gates_all.append(gates)\n",
    "\n",
    "\n",
    "    #create new df to show parameters\n",
    "    df_new =pd.DataFrame({'name': name, 'num_qubits': numbers, 'num_clbits': clbits, 'params': params, 'gates': gates_all})\n",
    "    df_new = df_new.sort_values(by='num_qubits', ascending=False)\n",
    "    df_new = df_new[df_new['num_qubits'] == 2].reset_index()\n",
    "\n",
    "    res = dict()\n",
    "    res['noisy_expectation'] = dict_['noisy_expectation']\n",
    "    res['num_layers'] = dict_['num_layers']\n",
    "    #res['observable'] = dict_['obervable']\n",
    "    tmp = count_gate_paris(df_new, 'gates')\n",
    "    for i in tmp.keys():\n",
    "        res['count_' + i] = tmp[i]\n",
    "    res['target'] = dict_['ideal_expectation']\n",
    "\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5957224861016154"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick and dirty test for r2-score without using observable\n",
    "a = list()\n",
    "for i in range(1000):\n",
    "    a.append(extract_features(f\"./../pickles/circ_{i}.pickle\"))\n",
    "df = pd.DataFrame(a)\n",
    "\n",
    "train_x = df[:900].drop(columns=['target'])\n",
    "train_y = df[:900]['target']\n",
    "\n",
    "test_x = df[900:].drop(columns=['target'])\n",
    "test_y = df[900:]['target']\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model = model.fit(train_x, train_y)\n",
    "\n",
    "metrics.r2_score(test_y, model.predict(test_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectSeminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
